name: Performance

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:  # Allow manual runs

env:
  CARGO_TERM_COLOR: always
  CARGO_HOME: /home/runner/.cargo
  CARGO_INCREMENTAL: 0
  # Enable native CPU optimizations for maximum performance
  RUSTFLAGS: -C target-cpu=native

jobs:
  benchmark:
    name: Perf ${{ matrix.size }}MB L${{ matrix.level }} (${{ matrix.thread_mode }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        size: [1, 10, 100]
        level: [1, 3, 7, 9]
        thread_mode: [single, max]  # single=1 thread, max=all available cores

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential zlib1g-dev gzip

      - name: Build rigz
        run: cargo build --release

      - name: Build pigz
        run: make -C pigz

      - name: Detect cores and run benchmark
        run: |
          CORES=$(nproc)
          echo "Available cores: $CORES"
          
          if [ "${{ matrix.thread_mode }}" = "single" ]; then
            THREADS=1
          else
            THREADS=$CORES
          fi
          
          echo "Running with $THREADS threads"
          # Strict thresholds: rigz must beat pigz everywhere
          # L1-8: Speed must beat pigz (0% overhead), size within 5%
          # L9: Size must match pigz (0.5%), speed within 10%
          # Enable debug for L9 to diagnose GHA slowdown
          DEBUG_FLAG=""
          if [ "${{ matrix.level }}" = "9" ]; then
            DEBUG_FLAG="--debug"
          fi
          python3 scripts/benchmark_ci.py \
            --size ${{ matrix.size }} \
            --level ${{ matrix.level }} \
            --threads $THREADS \
            --data-type text \
            --output benchmark-results.json \
            $DEBUG_FLAG

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: bench-${{ matrix.size }}mb-l${{ matrix.level }}-${{ matrix.thread_mode }}
          path: benchmark-results.json

  compression-ratio:
    name: Ratio L${{ matrix.level }} (${{ matrix.thread_mode }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        level: [1, 6, 9]
        thread_mode: [single, max]

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential zlib1g-dev gzip

      - name: Build rigz
        run: cargo build --release

      - name: Build pigz
        run: make -C pigz

      - name: Check compression ratio
        run: |
          CORES=$(nproc)
          if [ "${{ matrix.thread_mode }}" = "single" ]; then
            THREADS=1
          else
            THREADS=$CORES
          fi
          
          # Strict thresholds based on level
          # L9 gets special treatment (size priority)
          # Enable debug for L9 to diagnose GHA slowdown
          DEBUG_FLAG=""
          if [ "${{ matrix.level }}" = "9" ]; then
            DEBUG_FLAG="--debug"
          fi
          python3 scripts/benchmark_ci.py \
            --size 10 \
            --level ${{ matrix.level }} \
            --threads $THREADS \
            --data-type text \
            --output ratio-results.json \
            $DEBUG_FLAG

  summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [benchmark, compression-ratio]
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results

      - name: Summarize results
        run: |
          echo "## Performance Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          passed=0
          failed=0
          
          for f in results/*/benchmark-results.json; do
            if [ -f "$f" ]; then
              status=$(cat "$f" | python3 -c "import json,sys; d=json.load(sys.stdin); print('pass' if d.get('passed', False) else 'fail')" 2>/dev/null || echo "unknown")
              if [ "$status" = "pass" ]; then
                passed=$((passed + 1))
              else
                failed=$((failed + 1))
              fi
            fi
          done
          
          echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| ✅ Passed | $passed |" >> $GITHUB_STEP_SUMMARY
          echo "| ❌ Failed | $failed |" >> $GITHUB_STEP_SUMMARY
