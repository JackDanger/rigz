# gzippy - The Fastest Parallel Gzip

## Prime Directive

**gzippy must be the fastest gzip implementation in existence.**

We will do **any amount of work** to beat all competitors:
- Re-implement entire libraries from scratch if needed
- Write thousands of lines of custom code
- Study other libraries' source code in detail and match or exceed every optimization
- No complexity is too high if it yields measurable performance gains

### Non-Negotiable Constraints
1. Full gzip/gunzip compatibility (RFC 1952)
2. Drop-in replacement for gzip CLI
3. Matching or beating pigz compression ratio at each level
4. When making a tradeoff, you MUST choose the most performant option

### Performance Requirements
- **Compression**: Beat pigz at all levels and thread counts
- **Decompression**: Beat rapidgzip on ALL file types (BGZF, pigz, gzip)

## Architecture

### Compression Levels

| Levels | Library | Strategy | Block Style |
|--------|---------|----------|-------------|
| L1-L5 | libdeflate | Parallel independent | BGZF markers |
| L6-L9 | zlib-ng | Pipelined with dictionary | Single stream |
| L10-L12 | libdeflate L10-12 | Parallel independent | BGZF markers, 512KB blocks |

### Decompression Architecture

| File Type | Strategy | Target Performance |
|-----------|----------|-------------------|
| BGZF (gzippy output) | Parallel via embedded markers | 3500+ MB/s |
| Multi-member (pigz) | Parallel per-member | 2500+ MB/s |
| Single-member (gzip) | Marker-based speculative parallel | 2500+ MB/s |

### Key Decompression Modules

| File | Purpose |
|------|---------|
| `decompression.rs` | Main entry point, routes to appropriate backend |
| `ultra_decompress.rs` | Dispatcher for BGZF/multi-member/single |
| `marker_decode.rs` | Marker-based speculative decoding (like rapidgzip) |
| `isal.rs` | High-performance inflater (libdeflate, statically linked) |

## Marker-Based Speculative Decoding

The key to matching rapidgzip on arbitrary gzip files:

1. **uint16_t output buffers** - Values 0-255 are bytes, 256+ are markers
2. **Markers encode unresolved back-refs** - `marker = 32768 + (distance - decoded_bytes - 1)`
3. **Immediate decoding** - Start at any position without waiting for window
4. **Parallel marker replacement** - Once window is known, replace markers in parallel

### Chunk Processing Pipeline

```
[Input File] 
    ↓ (partition at 4MB spacing)
[Chunk 0] [Chunk 1] [Chunk 2] ... [Chunk N]
    ↓ (parallel decode with markers)
[Decode] → [Markers + Data]
    ↓ (propagate windows)
[Window 0] → [Replace Markers 1] → [Window 1] → [Replace Markers 2] → ...
    ↓ (write output)
[Final Output]
```

### L10-L12: Ultra Compression (Independent Blocks)
- **Library**: libdeflate L10-L12 (exhaustive search)
- **Strategy**: Large 512KB blocks for better context
- **Compression**: Near-zopfli ratio (4-5% smaller than gzip -9)
- **Decompression**: Parallel (blocks decompress independently)

## Performance Targets

| Metric | Target | Baseline |
|--------|--------|----------|
| BGZF decompression | 3500+ MB/s | rapidgzip: 3168 MB/s |
| gzip decompression (14 threads) | 2500+ MB/s | rapidgzip: 2791 MB/s |
| gzip decompression (1 thread) | 1000+ MB/s | gzip: 1018 MB/s |
| Compression L1-L5 | Beat pigz | - |
| Compression L6-L9 | Beat pigz | - |
| Compression L10-L12 | Beat zopfli speed, match ratio | - |

## Threading Model

### Compression (from pigz)
1. **N compress workers** claim blocks via atomic counter
2. **1 dedicated writer** writes blocks in order  
3. Workers never block on I/O
4. Brief spin-wait for low-latency handoff

### Decompression (from rapidgzip)
1. **Chunk partitioning** at fixed spacing (4MB default)
2. **Parallel speculative decode** with marker tracking
3. **Window propagation** through chunk chain
4. **Parallel marker replacement** via thread pool

## What We've Learned

### What Works
1. **4-byte block sizes** in BGZF headers (supports >64KB blocks)
2. **Pre-allocated output buffers** with direct parallel writes
3. **Lock-free work distribution** via atomic counters
4. **libdeflate for verified blocks** once window is known
5. **Chunk spacing** (guess positions) rather than block finding
6. **Statically-linked dependencies** - no runtime library issues

### What Doesn't Work
1. **Finding actual block boundaries** - Success rate too low (<5%)
2. **Blocking on window availability** - Must use markers instead
3. **Sequential marker replacement** - Must be parallel
4. **Independent blocks at L9** - 4% larger output
5. **Capping threads at physical_cores** - VMs underreport
6. **ISA-L FFI on ARM** - Complex struct layout (200KB+), pure C fallback anyway

## Build & Dependencies

gzippy uses only statically-linked dependencies for maximum portability:
- **libdeflate** (via libdeflater crate) - Fast inflate/deflate
- **zlib-ng** (via flate2 with zlib-ng feature) - CRC32 and streaming

```toml
[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"
strip = true
```

**No external library dependencies** - The binary is fully self-contained:
```bash
$ ldd target/release/gzippy  # Linux
        linux-vdso.so.1
        libc.so.6
$ otool -L target/release/gzippy  # macOS
        /usr/lib/libiconv.2.dylib
        /usr/lib/libSystem.B.dylib
```

## Pre-commit Checks

A pre-commit hook runs:
1. `cargo fmt --check`
2. `cargo clippy --all-targets --all-features -- -D warnings`

To skip (emergency only): `git commit --no-verify`

## CI Architecture

### Critical CI Rules
1. **Never use `-C target-cpu=native`** - Causes SIGILL on heterogeneous CI runners
2. **Use adaptive benchmarking** - Run until stdev < 5% of mean (min 5, max 30 trials)
3. **All deps statically linked** - No ISA-L or other external libs to build

### Workflow Design (4-stage pipeline)
1. **Build** - Build all tools once, upload as artifacts
2. **Prepare Data** - Generate test data, compress with all tools, upload
3. **Benchmark** - Download artifacts, run adaptive benchmarks
4. **Summary** - Aggregate results, post to PR

## Debug Mode

Set `GZIPPY_DEBUG=1` to enable timing diagnostics during compression.

## Current Status (Jan 2026)

### Compression: ✅ Complete
- Beats pigz at all levels
- L10-L12 ultra compression (near-zopfli ratios)

### Decompression: ✅ Core Complete
- ✅ BGZF files: 3400+ MB/s (beats rapidgzip)
- ✅ Marker-based speculative decoding
- ✅ Chunk spacing strategy
- ✅ libdeflate integration (statically linked)
- ✅ Parallel marker replacement pipeline

### Architecture Decisions
- **libdeflate over ISA-L**: ISA-L's complex FFI (200KB+ struct) and ARM fallback to pure C made libdeflate the pragmatic choice. libdeflate is ~90% of ISA-L's SIMD speed with simpler integration.
- **Static linking only**: All dependencies are statically linked - no runtime library discovery issues.
