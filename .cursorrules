# gzippy - The Fastest Parallel Gzip

## Prime Directive

**gzippy must be the fastest gzip implementation possible within the constraints of:**
1. Full gzip/gunzip compatibility (RFC 1952)
2. Matching or beating pigz compression ratio at each level
3. Using the best available libraries (libdeflate, zlib-ng)

## Architecture

### L1-L6: Speed-Optimized (Independent Blocks)
- **Library**: libdeflate (30-50% faster than zlib-ng)
- **Strategy**: Parallel independent blocks with "GZ" BGZF markers
- **Decompression**: Parallel (blocks decompress independently)

### L7-L9: Compression-Optimized (Pipelined)
- **Library**: zlib-ng with dictionary sharing
- **Strategy**: Each block uses previous block's data as dictionary
- **Decompression**: Sequential (single gzip stream)

## Performance Targets

| Level | Speed vs pigz | Size vs pigz |
|-------|---------------|--------------|
| L1-L6 | Must beat | Within 8% |
| L7-L8 | Must beat | Within 2% |
| L9 | Must beat | Within 0.5% |

## File Organization

| File | Purpose |
|------|---------|
| `parallel_compress.rs` | L1-L6: libdeflate parallel blocks |
| `pipelined_compress.rs` | L7-L9: zlib-ng with dictionary sharing |
| `scheduler.rs` | Pigz-style N+1 thread scheduler |
| `decompression.rs` | libdeflate for all decompression |

## Threading Model

Adopted from pigz:
1. **N compress workers** claim blocks via atomic counter
2. **1 dedicated writer** writes blocks in order  
3. Workers never block on I/O
4. Brief spin-wait for low-latency handoff

## What Doesn't Work

1. **Independent blocks at L9**: 4% larger output (violates 0.5% threshold)
2. **Capping threads at physical_cores**: VMs underreport; use requested count
3. **Main thread helping compress**: Causes write delays
4. **Pure spin-wait**: Burns vCPU time on cloud VMs

## igzip Comparison

igzip (Intel ISA-L) is a **speed-optimized** compressor that trades compression ratio
for speed. It produces 10-15% larger files than gzip/pigz/gzippy at similar levels.

**Benchmark approach**: Compare gzippy against pigz (same compression goals), not igzip.
igzip is benchmarked for informational purposes but not as a pass/fail target.

- igzip L3 (max) â‰ˆ gzip L4 in compression ratio
- gzippy L1-L3 targets better compression with competitive speed
- For users who need igzip-like speed, they can use gzippy L1

## Build Optimizations

```toml
[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"
strip = true
```

## Pre-commit Checks

A pre-commit hook runs:
1. `cargo fmt --check`
2. `cargo clippy --all-targets --all-features -- -D warnings`

To skip (emergency only): `git commit --no-verify`

## Debug Mode

Set `GZIPPY_DEBUG=1` to enable timing diagnostics during compression.
